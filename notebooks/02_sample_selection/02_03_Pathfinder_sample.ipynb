{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "substantial-lewis",
   "metadata": {},
   "source": [
    "# Creating pathfinder subsample\n",
    "\n",
    "June 20, 2022  \n",
    "Gully & Ryan H.\n",
    "\n",
    "The goal of this notebook is to make the pathfinder sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightkurve as lk\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "sns.set_context('notebook', font_scale=1.5)\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['EPIC','Campaign','Teff','log g','Prot','ΔProt','hpeak','Rvar','Kp','MG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/Reinhold_Hekker2020/table2.dat', \n",
    "                 delim_whitespace=True, names=names, na_values='---')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-qualification",
   "metadata": {},
   "source": [
    "Looks good!  We see the same trend we had in our proposal figure 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-upper",
   "metadata": {},
   "source": [
    "## Select a subsample of sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-porcelain",
   "metadata": {},
   "source": [
    "First search for some high amplitude variable stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion1 = (df.Prot > 1) & (df.Prot < 10)\n",
    "criterion2 = (df.Rvar > 0.5) & (df.Rvar < 20)\n",
    "criterion3 = (df.Teff > 4000) & (df.Teff < 4500)\n",
    "criteria = criterion1 & criterion2 & criterion3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(df.Prot, df.Rvar, '.', alpha=0.02);\n",
    "plt.plot(df.Prot[criterion3], df.Rvar[criterion3], '.', alpha=0.1);\n",
    "plt.plot(df.Prot[criteria], df.Rvar[criteria], '.', alpha=0.5);\n",
    "#plt.ylim(3e2, 2e5)\n",
    "plt.xlim(1e0, 1e2)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('$P_{\\mathrm{rot}}$')\n",
    "plt.ylabel('$\\propto$ Amplitude (%)')\n",
    "plt.title('Reinhold & Hekker 2020 Table 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[criteria].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-evening",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset=df[criteria].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-shark",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-auction",
   "metadata": {},
   "source": [
    "## Make a subsub sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-packing",
   "metadata": {},
   "source": [
    "### Prepopulate our columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-price",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset['N_EVEREST'] = np.NaN\n",
    "df_subset['N_TESS_SPOC'] = np.NaN\n",
    "df_subset['Period_TESS'] = 0\n",
    "df_subset['Amplitude_TESS'] = 0\n",
    "df_subset['Period_K2'] = 0\n",
    "df_subset['Amplitude_K2'] = 0\n",
    "df_subset['Sector'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-portrait",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiny = df_subset.head(15)\n",
    "df_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2791944",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiny.iloc[0].to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-military",
   "metadata": {},
   "source": [
    "### Predownload so that it runs faster later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-thumb",
   "metadata": {},
   "source": [
    "Let's find one of the sources that *also* has TESS data available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-relevance",
   "metadata": {},
   "source": [
    "Delete the cell below if you want to run on the entire subset of 400+ sources..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-fusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sources = len(df_subset)\n",
    "n_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-browser",
   "metadata": {},
   "source": [
    "We want to have at least 1 EVEREST lightcurve and 1 SPOC lightcurve for all sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for i in tqdm(range(n_sources)):\n",
    "    # find the name of the star\n",
    "    name = 'EPIC ' + df_subset.iloc[i].EPIC.astype(int).astype(str)\n",
    "    \n",
    "    # find the TESS lightcurve for the star\n",
    "    sr = lk.search_lightcurve(name, mission=\"TESS\")\n",
    "    \n",
    "    # find the number of TESS missions for the star\n",
    "    df_subset.loc[i, 'N_TESS_SPOC'] = len(sr)\n",
    "    \n",
    "    # check if there is TESS data available\n",
    "    if len(sr) > 0:\n",
    "        # download the data for the lightcurve\n",
    "        lc = sr[0].download()\n",
    "    \n",
    "        # remove NaNs and normalize the data\n",
    "        lc = lc.remove_nans().normalize()\n",
    "    \n",
    "        # find the amplitude percentage\n",
    "        vector = lc.flux.value\n",
    "        lo, hi = np.percentile(vector, (5, 95))\n",
    "        peak_to_valley = hi-lo\n",
    "    \n",
    "        # add the amplitude to the data table\n",
    "        df_subset.loc[i, 'Amplitude_TESS'] = peak_to_valley\n",
    "        \n",
    "        # change the lightcurve into a periodogram and find its period\n",
    "        period = float(lc.to_periodogram().period_at_max_power.to_value())\n",
    "\n",
    "        # add the period to the data table\n",
    "        df_subset.loc[i, 'Period_TESS'] = period\n",
    "        \n",
    "#----------------------------------------------------------------------------\n",
    "# Now for the Kepler data\n",
    "\n",
    "        \n",
    "    # find the Kepler lightcurve for the star\n",
    "    sr = lk.search_lightcurve(name, mission=\"K2\", author='EVEREST')\n",
    "    \n",
    "    # find the number of Kepler missions for the star\n",
    "    df_subset.loc[i, 'N_EVEREST'] = len(sr)\n",
    "    \n",
    "    # check if there is Kepler data available\n",
    "    if len(sr) > 0:\n",
    "        # download the data for the lightcurve\n",
    "        lc = sr[0].download()\n",
    "    \n",
    "        # remove NaNs and normalize the data\n",
    "        lc = lc.remove_nans().normalize()\n",
    "\n",
    "        # find the amplitude percentage\n",
    "        vector = lc.flux.value\n",
    "        lo, hi = np.percentile(vector, (5, 95))\n",
    "        peak_to_valley = hi-lo\n",
    "\n",
    "        # add the data to the table\n",
    "        df_subset.loc[i, 'Amplitude_K2'] = peak_to_valley\n",
    "\n",
    "        # change the lightcurve into a periodogram and find its period\n",
    "        period = float(lc.to_periodogram().period_at_max_power.to_value())\n",
    "\n",
    "        # add the period to the data table\n",
    "        df_subset.loc[i, 'Period_K2'] = period\n",
    "    \n",
    "    # Todo \n",
    "    ## Populate the Amplitde and Period columns\n",
    "    # df_subset.loc[i,'Amplitude'] = ...\n",
    "    # df_subset.loc[i,'Period'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-electron",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-facing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-sauce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.to_csv('pathfinder_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-residence",
   "metadata": {},
   "source": [
    "## Spot check one source..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'EPIC 202059229'\n",
    "\n",
    "# find the TESS lightcurve for the star\n",
    "sr = lk.search_lightcurve(name, author=\"EVEREST\")\n",
    "\n",
    "# check if there is TESS data available\n",
    "if len(sr) > 0:\n",
    "    # download the data for the lightcurve\n",
    "    lc = sr[0].download()\n",
    "\n",
    "    # remove NaNs and normalize the data\n",
    "    lc = lc.remove_nans().normalize()\n",
    "\n",
    "    # find the amplitude percentage\n",
    "    vector = lc.flux.value\n",
    "    lo, hi = np.percentile(vector, (5, 95))\n",
    "    peak_to_valley = hi-lo\n",
    "\n",
    "    # add the data to the table\n",
    "    df_subset.loc[i, 'Amplitude_TESS'] = float(peak_to_valley)\n",
    "    \n",
    "    period = float(lc.to_periodogram().period_at_max_power.to_value())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc.to_periodogram().plot(view='period', scale='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-chaos",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-remains",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-journey",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-matrix",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-wages",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-playing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-faith",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "minute-journal",
   "metadata": {},
   "source": [
    "### Example manipulations ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-release",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr.table.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (sr.table['author'] == 'EVEREST').data\n",
    "mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-penetration",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = lk.search_lightcurve(\"EPIC 202059229\", mission='TESS')\n",
    "sr\n",
    "lc = sr[0].download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-visit",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = lc.remove_nans().normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-wealth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = lc.flux.value\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "lo, hi = np.percentile(vector, (5, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-mortality",
   "metadata": {},
   "outputs": [],
   "source": [
    "lo, hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = lc.normalize().plot()\n",
    "ax.axhline(hi)\n",
    "ax.axhline(lo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_to_valley = hi-lo\n",
    "peak_to_valley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-constraint",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sr = sr.table.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-investing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-strategy",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-integrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = lk.search_lightcurve(\"EPIC 211071889\", author=\"EVEREST\", mission=\"K2\")\n",
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-championship",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_K2 = sr.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-arabic",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = lk.search_lightcurve(\"EPIC 211071889\", author=\"SPOC\", mission=\"TESS\")\n",
    "sr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_TESS = sr[0].download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = np.percentile(lc_K2.flux, 98)\n",
    "lc_K2 = lc_K2/scalar\n",
    "ax = lc_K2.plot()\n",
    "ax.axhline(1.0, linestyle='dashed')\n",
    "ax.axhline(0.93, linestyle='dotted', color='#d35400', label='7 % flux loss')\n",
    "ax.set_title('K2 data')\n",
    "ax.set_ylim(0.8, 1.1)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_TESS = lc_TESS.remove_nans().bin(binsize=5)\n",
    "scalar = np.nanpercentile(lc_TESS.flux, 98)\n",
    "lc_TESS = lc_TESS/scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = lc_TESS.plot()\n",
    "ax.axhline(1.0, linestyle='dashed')\n",
    "ax.axhline(0.93, linestyle='dotted', color='#d35400', label='7 % flux loss')\n",
    "ax.axhline(0.955, linestyle='solid', color='#2ecc71', label='4.5 % flux loss')\n",
    "ax.set_title('TESS data')\n",
    "ax.set_ylim(0.8, 1.1)\n",
    "ax.legend(fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-vacuum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-mining",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-helen",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sr) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc=sr.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = lc.remove_outliers(sigma=4,sigma_upper=3).normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg = lc.to_periodogram(nterms=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pg.plot(view='period', scale='log')\n",
    "ax.axvline(pg.period_at_max_power.value, linestyle='dotted', label=f'{pg.period_at_max_power:0.5f}')\n",
    "ax.axvline(6.70, linestyle='dashed', label='6.7 d (Reinhold & Hekker 2020)', color = 'red')\n",
    "ax.legend(fontsize = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.period_at_max_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-found",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = lc.plot()\n",
    "pg.model(lc.time).plot(ax=ax)\n",
    "pg.model(lc.time, frequency=pg.frequency_at_max_power/2).plot(ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b35b03c3ac9cbf5001493e5ff23c42dd8f9188277db64dd08850bcd62e251f33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
