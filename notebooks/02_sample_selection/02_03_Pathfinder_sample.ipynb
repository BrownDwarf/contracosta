{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "substantial-lewis",
   "metadata": {},
   "source": [
    "# Creating pathfinder subsample\n",
    "\n",
    "June 21, 2022  \n",
    "Gully & Ryan H.\n",
    "\n",
    "The goal of this notebook is to make the pathfinder sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightkurve as lk\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import astropy.units as u\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "sns.set_context('notebook', font_scale=1.5)\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['EPIC','Campaign','Teff','log g','Prot','Î”Prot','hpeak','Rvar','Kp','MG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/Reinhold_Hekker2020/table2.dat', \n",
    "                 delim_whitespace=True, names=names, na_values='---')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-qualification",
   "metadata": {},
   "source": [
    "Looks good!  We see the same trend we had in our proposal figure 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-upper",
   "metadata": {},
   "source": [
    "## Select a subsample of sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-porcelain",
   "metadata": {},
   "source": [
    "First search for some high amplitude variable stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion1 = (df.Prot > 1) & (df.Prot < 10)\n",
    "criterion2 = (df.Rvar > 0.5) & (df.Rvar < 20)\n",
    "criterion3 = (df.Teff > 4000) & (df.Teff < 4500)\n",
    "criteria = criterion1 & criterion2 & criterion3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(df.Prot, df.Rvar, '.', alpha=0.02);\n",
    "plt.plot(df.Prot[criterion3], df.Rvar[criterion3], '.', alpha=0.1);\n",
    "plt.plot(df.Prot[criteria], df.Rvar[criteria], '.', alpha=0.5);\n",
    "#plt.ylim(3e2, 2e5)\n",
    "plt.xlim(1e0, 1e2)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('$P_{\\mathrm{rot}}$')\n",
    "plt.ylabel('$\\propto$ Amplitude (%)')\n",
    "plt.title('Reinhold & Hekker 2020 Table 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[criteria].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-evening",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset=df[criteria].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-shark",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-auction",
   "metadata": {},
   "source": [
    "## Make a subsub sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-packing",
   "metadata": {},
   "source": [
    "### Prepopulate our columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-price",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset['N_EVEREST'] = np.NaN\n",
    "df_subset['N_TESS_SPOC'] = np.NaN\n",
    "df_subset['Period_TESS'] = 0\n",
    "df_subset['Amplitude_TESS'] = 0\n",
    "df_subset['Period_K2'] = 0\n",
    "df_subset['Amplitude_K2'] = 0\n",
    "df_subset['Sector'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-portrait",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiny = df_subset.head(15)\n",
    "df_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2791944",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiny.iloc[0].to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-military",
   "metadata": {},
   "source": [
    "### Predownload so that it runs faster later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-thumb",
   "metadata": {},
   "source": [
    "Let's find one of the sources that *also* has TESS data available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-relevance",
   "metadata": {},
   "source": [
    "Delete the cell below if you want to run on the entire subset of 400+ sources..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed97bd4a",
   "metadata": {},
   "source": [
    "df_subset = df_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sources = len(df_subset)\n",
    "n_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-browser",
   "metadata": {},
   "source": [
    "We want to have at least 1 EVEREST lightcurve and 1 SPOC lightcurve for all sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ac958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data(data):\n",
    "    # data = [mission, index, search result]\n",
    "    mission, idx, sr = data\n",
    "    def add_data_helper(mission, idx, sr, num):\n",
    "        lc = sr[num].download()\n",
    "        # remove NaNs and normalize the data\n",
    "        lc = lc.remove_nans().remove_outliers()\n",
    "        # find the amplitude percentage\n",
    "        vector = lc.flux.value\n",
    "        lo, hi = np.percentile(vector, (5, 95))\n",
    "        peak_to_valley = hi-lo\n",
    "        # add the data to the table\n",
    "        df_subset.loc[idx, f'Amplitude_{mission}'] = peak_to_valley\n",
    "        # change the lightcurve into a periodogram and find its period\n",
    "        period = float(lc.to_periodogram().period_at_max_power.to_value())\n",
    "        # add the period to the data table\n",
    "        df_subset.loc[idx, f'Period_{mission}'] = period\n",
    "        if mission == 'TESS':\n",
    "            # find the sector number and add it to the data table\n",
    "            df_subset.loc[idx, 'Sector'] = lc.sector\n",
    "\n",
    "    if len(sr) > 0:\n",
    "        try:\n",
    "            add_data_helper(mission, idx, sr, 0)\n",
    "        except:\n",
    "            add_data_helper(mission, idx, sr, 1)\n",
    "        finally:\n",
    "            return\n",
    "\n",
    "def download(data):\n",
    "    name, index, mission = data\n",
    "    if mission == 0:\n",
    "        sr = lk.search_lightcurve(name, mission='TESS')\n",
    "        df_subset.loc[index, 'N_TESS_SPOC'] = len(sr)\n",
    "    elif mission == 1:\n",
    "        sr = lk.search_lightcurve(name, author='EVEREST')\n",
    "        df_subset.loc[index, 'N_EVEREST'] = len(sr)\n",
    "    return index, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc72b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    start = time.time()\n",
    "\n",
    "    TESS_download = []\n",
    "    K2_download = []\n",
    "    for i in range(n_sources):\n",
    "        # find the name of the star\n",
    "        name = 'EPIC ' + df_subset.iloc[i].EPIC.astype(int).astype(str)\n",
    "        TESS_download.append([name, i, 0])\n",
    "        K2_download.append([name, i, 1])\n",
    "\n",
    "\n",
    "    TESS_data = []\n",
    "    K2_data = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "        TESS_sr = executor.map(download, TESS_download)\n",
    "        K2_sr = executor.map(download, K2_download)\n",
    "\n",
    "        for result in TESS_sr:\n",
    "            TESS_data.append(['TESS', result[0], result[1]])\n",
    "        for result in K2_sr:\n",
    "            K2_data.append(['K2', result[0], result[1]])\n",
    "\n",
    "    for i in range(n_sources):\n",
    "        add_data(TESS_data[i])\n",
    "        add_data(K2_data[i])\n",
    "    \n",
    "    end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df52989",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3bdb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ad0d7b",
   "metadata": {},
   "source": [
    "## Complitation times\n",
    "\n",
    "**15 Stars:**  \n",
    "Desktop:  \n",
    "fresh download time ~ 42 seconds  \n",
    "pre-downloaded time ~ 33.65 seconds  \n",
    "cached time ~ 2.6 seconds  \n",
    "  \n",
    "\n",
    "Laptop:  \n",
    "fresh download time ~ 46 seconds  \n",
    "pre-downloaded time ~ 33.8 seconds  \n",
    "cached time ~ 2.39 seconds  \n",
    "\n",
    "------------------------------------------------------------  \n",
    "\n",
    "**416 Stars:**  \n",
    "Desktop:  \n",
    "fresh download time ~ 1359.3 seconds ~ 22.6 minutes  \n",
    "pre-downloaded time ~ 808 seconds ~ 13.5 minutes  \n",
    "cached time ~ 100 seconds  \n",
    "  \n",
    "\n",
    "Laptop:  \n",
    "fresh download time ~ 1747.5 seconds ~ 29.1 minutes  \n",
    "pre-downloaded time ~ 936.8 seconds ~ 15.6 minutes  \n",
    "cached time ~ 66.4 seconds  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-sauce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.to_csv('pathfinder_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-residence",
   "metadata": {},
   "source": [
    "## Spot check one source..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'EPIC 201245978'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112d9227",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_tess = lk.search_lightcurve(name, mission='TESS')#.download().remove_nans().remove_outliers()\n",
    "len(lc_tess)\n",
    "# lc_tess.plot()\n",
    "# lc_tess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = lk.search_lightcurve(name, author=\"EVEREST\")[0].download().remove_nans().remove_outliers()#.normalize().flatten()\n",
    "lc.plot()#.to_periodogram().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg = lc.to_periodogram()\n",
    "pg.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.period_at_max_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-remains",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'EPIC 220205464'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-journey",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.iloc[236].EPIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "download(name, \"TESS\", 236)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-wages",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d078767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpf = lk.search_targetpixelfile('EPIC 246979864', author='K2').download()\n",
    "pld = lk.correctors.PLDCorrector(tpf)\n",
    "corrected_lc = pld.correct().remove_outliers().to_periodogram().period_at_max_power\n",
    "corrected_lc.to_periodogram().period_at_max_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-playing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd648705",
   "metadata": {},
   "source": [
    "## Plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d94790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1d87ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.ylim(0.5, 10)\n",
    "plt.xlim(0.5, 10)\n",
    "plt.xlabel('$P_{\\mathrm{Kepler}}$')\n",
    "plt.ylabel('$P_{\\mathrm{TESS}}$')\n",
    "plt.title('Comparison between TESS and Kepler amplitudes')\n",
    "\n",
    "x = [0.5, 10]\n",
    "y = [0.5, 10]\n",
    "plt.plot(x, y)\n",
    "\n",
    "# plt.xticks(1)\n",
    "# plt.yscale()\n",
    "\n",
    "plt.plot(df_subset.Period_K2, df_subset.Period_TESS, 'r.')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5214eb",
   "metadata": {},
   "source": [
    "## Receate fig2.pdf plot from proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb6c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_subset.Period_K2, df_subset.Amplitude_K2, '.', color='black')\n",
    "plt.plot(df_subset.Period_TESS, df_subset.Amplitude_TESS, '.', color='red')\n",
    "\n",
    "# plt.ylim(3e2, 2e5)\n",
    "# plt.xlim(1e0, 1e2)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.axhline(1e3, linestyle='dotted', label='1%', color='purple')\n",
    "plt.axvline(27, linestyle='dashed', label='27 days', color='purple')\n",
    "plt.legend()\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.xlabel('$P_{\\mathrm{rot}}$')\n",
    "plt.ylabel('$\\propto$ Amplitude (%)')\n",
    "plt.title('Predicted for 4000 < $T_{\\mathrm{eff}}$ < 4500 in TESS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31cb09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da59bdb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bd1ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9259c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "minute-journal",
   "metadata": {},
   "source": [
    "### Example manipulations ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-release",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr.table.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (sr.table['author'] == 'EVEREST').data\n",
    "mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-penetration",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = lk.search_lightcurve(\"EPIC 202059229\", mission='TESS')\n",
    "sr\n",
    "lc = sr[0].download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-visit",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = lc.remove_nans().normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-wealth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = lc.flux.value\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "lo, hi = np.percentile(vector, (5, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-mortality",
   "metadata": {},
   "outputs": [],
   "source": [
    "lo, hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = lc.normalize().plot()\n",
    "ax.axhline(hi)\n",
    "ax.axhline(lo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_to_valley = hi-lo\n",
    "peak_to_valley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-constraint",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sr = sr.table.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-investing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-strategy",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-integrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = lk.search_lightcurve(\"EPIC 211071889\", author=\"EVEREST\", mission=\"K2\")\n",
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-championship",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_K2 = sr.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-arabic",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = lk.search_lightcurve(\"EPIC 211071889\", author=\"SPOC\", mission=\"TESS\")\n",
    "sr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_TESS = sr[0].download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = np.percentile(lc_K2.flux, 98)\n",
    "lc_K2 = lc_K2/scalar\n",
    "ax = lc_K2.plot()\n",
    "ax.axhline(1.0, linestyle='dashed')\n",
    "ax.axhline(0.93, linestyle='dotted', color='#d35400', label='7 % flux loss')\n",
    "ax.set_title('K2 data')\n",
    "ax.set_ylim(0.8, 1.1)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_TESS = lc_TESS.remove_nans().bin(binsize=5)\n",
    "scalar = np.nanpercentile(lc_TESS.flux, 98)\n",
    "lc_TESS = lc_TESS/scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = lc_TESS.plot()\n",
    "ax.axhline(1.0, linestyle='dashed')\n",
    "ax.axhline(0.93, linestyle='dotted', color='#d35400', label='7 % flux loss')\n",
    "ax.axhline(0.955, linestyle='solid', color='#2ecc71', label='4.5 % flux loss')\n",
    "ax.set_title('TESS data')\n",
    "ax.set_ylim(0.8, 1.1)\n",
    "ax.legend(fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-vacuum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-mining",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-helen",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sr) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc=sr.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = lc.remove_outliers(sigma=4,sigma_upper=3).normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg = lc.to_periodogram(nterms=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pg.plot(view='period', scale='log')\n",
    "ax.axvline(pg.period_at_max_power.value, linestyle='dotted', label=f'{pg.period_at_max_power:0.5f}')\n",
    "ax.axvline(6.70, linestyle='dashed', label='6.7 d (Reinhold & Hekker 2020)', color = 'red')\n",
    "ax.legend(fontsize = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.period_at_max_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-found",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = lc.plot()\n",
    "pg.model(lc.time).plot(ax=ax)\n",
    "pg.model(lc.time, frequency=pg.frequency_at_max_power/2).plot(ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b35b03c3ac9cbf5001493e5ff23c42dd8f9188277db64dd08850bcd62e251f33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
